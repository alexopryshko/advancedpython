[10 баллов] Разработать web-crawler и поиск для сайта https://docs.python.org (или любого другого контентного)
Crawler должен обходить только ссылки внутри указанного домена.
Скачивание ресурсов должно быть реализовано в нескольких параллельных корутинах для достижения максимальной скорости обкачки.
Скорость обкачки должна быть параметром краулера. Например, 10 rps должно означать, что в секунду должно быть не более 10 запросов на домен.
Каждая страница должна быть положена в индекс elasticsearch. Можно использовать библиотеку aioelasticsearch.

[5 баллов] Разработать api, используя aiohttp или sanic, которое будет отдавать результаты поиска

/api/v1/search
Должен принимать следующий параметры
q - текстовый запрос
limit - количество результатов
offset - офсет результатов
В ответ должен возвращать список результатов (ссылок на обкачиваемый сайт), отсортированные по релевантности